{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting SALib\n",
      "  Obtaining dependency information for SALib from https://files.pythonhosted.org/packages/e1/40/393b381779d379afbb0e281d9f69cb511022e41a726f7871a929faec2b11/salib-1.5.1-py3-none-any.whl.metadata\n",
      "  Using cached salib-1.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (4.66.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (1.4.2)\n",
      "Requirement already satisfied: matplotlib>=3.5 in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (from SALib) (3.8.0)\n",
      "Collecting multiprocess (from SALib)\n",
      "  Obtaining dependency information for multiprocess from https://files.pythonhosted.org/packages/b2/07/8cbb75d6cfbe8712d8f7f6a5615f083c6e710ab916b748fbb20373ddb142/multiprocess-0.70.17-py311-none-any.whl.metadata\n",
      "  Using cached multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (from SALib) (1.26.1)\n",
      "Requirement already satisfied: pandas>=2.0 in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (from SALib) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.9.3 in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (from SALib) (1.11.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.5->SALib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.5->SALib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.5->SALib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.5->SALib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.5->SALib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.5->SALib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.5->SALib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.5->SALib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=2.0->SALib) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=2.0->SALib) (2023.3)\n",
      "Collecting dill>=0.3.9 (from multiprocess->SALib)\n",
      "  Obtaining dependency information for dill>=0.3.9 from https://files.pythonhosted.org/packages/46/d1/e73b6ad76f0b1fb7f23c35c6d95dbc506a9c8804f43dda8cb5b0fa6331fd/dill-0.3.9-py3-none-any.whl.metadata\n",
      "  Using cached dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib>=3.5->SALib) (1.16.0)\n",
      "Using cached salib-1.5.1-py3-none-any.whl (778 kB)\n",
      "Using cached multiprocess-0.70.17-py311-none-any.whl (144 kB)\n",
      "Using cached dill-0.3.9-py3-none-any.whl (119 kB)\n",
      "Installing collected packages: dill, multiprocess, SALib\n",
      "Successfully installed SALib-1.5.1 dill-0.3.9 multiprocess-0.70.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install SALib tqdm joblib\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "from SALib.sample import sobol\n",
    "from tqdm import tqdm\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enzymic_amox(t,y, \n",
    "kcat1,\n",
    "kcat2,\n",
    "Km1,\n",
    "Km2,  \n",
    "Tmax, \n",
    "Ken,  \n",
    "kAB,  \n",
    "kAN,  \n",
    "kAOH, \n",
    "kNH):\n",
    "    FAB = 0\n",
    "    FNH = 0 \n",
    "    \n",
    "    CAB = y[0]\n",
    "    CAN = y[1]\n",
    "    CNH = y[2]\n",
    "    CAOH = y[3]\n",
    "\n",
    "    Cez = 1\n",
    "\n",
    "    # Consumo de ester\n",
    "    VAB = (kcat1*CAB*Cez)/((Km1*(1 + (CAN/kAN) + (CAOH/kAOH))) + CAB)\n",
    "    \n",
    "    # Hidrolise de amoxicilina\n",
    "    VAN = (kcat2*CAN*Cez)/((Km2*(1 + (CAB/kAB) + (CNH/kNH) + (CAOH/kAOH))) + CAN)\n",
    "    \n",
    "    # Enzima saturada com 6-apa\n",
    "    X   = CNH/(Ken + CNH)\n",
    "    \n",
    "    # Sintese enzimatica\n",
    "    VS  = VAB*Tmax*X\n",
    "\n",
    "    # Hidrolise de ester\n",
    "    Vh1 = (VAB - VS) \n",
    "\n",
    "    dy = np.zeros(4)\n",
    "\n",
    "    # C. ester\n",
    "    dy[0] = ((-(VS - VAN) - (Vh1 + VAN)) + FAB) \n",
    "    \n",
    "    # C. amox\n",
    "    dy[1] = (VS - VAN)                         \n",
    "    \n",
    "    # C. 6-apa\n",
    "    dy[2] = (-(VS - VAN) + FNH)                \n",
    "    \n",
    "    # C. POHPG\n",
    "    dy[3] =  (Vh1 + VAN)\n",
    "    \n",
    "    return np.array(dy)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kcat1        = 0.178 #Constante catalítica do consumo do éster (mmol/i.u. per min)\n",
    " \n",
    "kcat2        = 0.327 #Constante catalítica da hidrólise da amoxicilina (mmol/i.u. per min)\n",
    " \n",
    "Km1          = 7.905 #Constante de Michaelis-Menten ou constante de afinidade para consumo do éster(mM) \n",
    " \n",
    "Km2          = 12.509 #Constante de Michaelis-Menten ou constante de afinidade para hidrólise da amoxicilina(mM)\n",
    " \n",
    "Tmax         = 0.606 #Taxa de conversão máxima do complexo acil-enzima-núcleo em produto\n",
    " \n",
    "Ken          = 14.350 #Constante de adsorção do 6-APA\n",
    " \n",
    "kAB          = 3.78 #Constante de inibição do éster (POHPGME)(mM)\n",
    " \n",
    "kAN          = 9.174 #Constante de inibição da amoxicilina (mM)\n",
    " \n",
    "kAOH         = 10.907 #Constante de inibição do POHPG, produto da hidr�lise da amoxicilina (mM)\n",
    " \n",
    "kNH          = 62.044 #Constante de inibição do 6-APA\n",
    "\n",
    "P = [kcat1,kcat2,Km1,Km2,Tmax,Ken,kAB,kAN,kAOH,kNH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ode15s_amox(P, CI, t):\n",
    "    return scipy.integrate.solve_ivp(enzymic_amox,t_span=(t[0],t[-1]),t_eval=t,y0=CI,method='RK45',args=P).y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inital_conditions = {\n",
    "    '80_60':[80.0,0.0,60.0,0.0],    # High ester\n",
    "    '30_05':[30.0,0.0,5.0,0.0],     # Low both\n",
    "    '40_22':[40.0,0.0,22.0,0.0],    # Low ester\n",
    "    '40_100':[40.0,0.0,100,0.0],     # High apa\n",
    "    '30_30':[30.0, 0.0, 30.0, 0.0], # Same concentration\n",
    "    '80_05':[80.0, 0.0, 5.0, 0.0]   # High ester Low apa\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_output(params):\n",
    "    kcat1, kcat2, Km1, Km2, Tmax, Ken, kAB, kAN, kAOH, kNH, CAB0, CAN0, CNH0, CAOH0 = params\n",
    "    initial_state = [CAB0, CAN0, CNH0, CAOH0]\n",
    "    sol = ode15s_amox(params[:-4],initial_state,t_eval)\n",
    "    return sol  # Transpose to get time points as rows and variables as columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bounds(P, factor=2.6):\n",
    "    bounds = []\n",
    "    for i, param in enumerate(P):\n",
    "        if i == 4:  # Tmax (special case)\n",
    "            bounds.append([0, 1])\n",
    "        else:\n",
    "            lower_bound = param * (1 - factor)\n",
    "            upper_bound = param * (1 + factor)\n",
    "            if lower_bound < 0:\n",
    "                lower_bound = 0.01\n",
    "            bounds.append([lower_bound, upper_bound])\n",
    "\n",
    "    return bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01, 0.6408], [0.01, 1.1772], [0.01, 28.458000000000002], [0.01, 45.0324], [0, 1], [0.01, 51.66], [0.01, 13.607999999999999], [0.01, 33.0264], [0.01, 39.2652], [0.01, 223.3584]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate bounds for the parameters in P\n",
    "param_bounds = calculate_bounds(P)\n",
    "print(param_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2)\n"
     ]
    }
   ],
   "source": [
    "# Define the problem\n",
    "problem = {\n",
    "    'num_vars': 10,\n",
    "    'names': [\n",
    "        'kcat1',\n",
    "        'kcat2',\n",
    "        'Km1',\n",
    "        'Km2',  \n",
    "        'Tmax', \n",
    "        'Ken',  \n",
    "        'kAB',  \n",
    "        'kAN',  \n",
    "        'kAOH', \n",
    "        'kNH'],\n",
    "     'bounds': np.array(param_bounds)\n",
    "}\n",
    "print(problem['bounds'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.    2.5   5.    7.5  10.   12.5  15.   17.5  20.   22.5  25.   27.5\n",
      "  30.   32.5  35.   37.5  40.   42.5  45.   47.5  50.   52.5  55.   57.5\n",
      "  60.   62.5  65.   67.5  70.   72.5  75.   77.5  80.   82.5  85.   87.5\n",
      "  90.   92.5  95.   97.5 100.  102.5 105.  107.5 110.  112.5 115.  117.5\n",
      " 120.  122.5 125.  127.5 130.  132.5 135.  137.5 140.  142.5 145.  147.5\n",
      " 150.  152.5 155.  157.5 160.  162.5 165.  167.5 170.  172.5 175.  177.5\n",
      " 180.  182.5 185.  187.5 190.  192.5 195.  197.5 200.  202.5 205.  207.5\n",
      " 210.  212.5 215.  217.5 220.  222.5 225.  227.5 230.  232.5 235.  237.5\n",
      " 240.  242.5 245.  247.5 250.  252.5 255.  257.5 260.  262.5 265.  267.5\n",
      " 270.  272.5 275.  277.5 280.  282.5 285.  287.5 290.  292.5 295.  297.5\n",
      " 300.  302.5 305.  307.5 310.  312.5 315.  317.5 320.  322.5 325.  327.5\n",
      " 330.  332.5 335.  337.5 340.  342.5 345.  347.5 350.  352.5 355.  357.5\n",
      " 360.  362.5 365.  367.5 370.  372.5 375.  377.5 380.  382.5 385.  387.5\n",
      " 390.  392.5 395.  397.5 400.  402.5 405.  407.5 410.  412.5 415.  417.5\n",
      " 420.  422.5 425.  427.5 430.  432.5 435.  437.5 440.  442.5 445.  447.5\n",
      " 450.  452.5 455.  457.5 460.  462.5 465.  467.5 470.  472.5 475.  477.5\n",
      " 480.  482.5 485.  487.5 490.  492.5 495.  497.5 500. ]\n",
      "N samples:  (45056, 10)\n"
     ]
    }
   ],
   "source": [
    "# Generate samples using Sobol sequence\n",
    "param_values = sobol.sample(problem, 2048)\n",
    "t_eval = np.linspace(0, 500, 201)\n",
    "print(t_eval)\n",
    "print(\"N samples: \",param_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting... 80_60 \t Time:  13:33:30.692476\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'enzymic_amox' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\artur\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"C:\\Users\\artur\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\artur\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\artur\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\artur\\AppData\\Local\\Temp\\ipykernel_13428\\1711729331.py\", line 4, in model_output\n  File \"C:\\Users\\artur\\AppData\\Local\\Temp\\ipykernel_13428\\1111278988.py\", line 2, in ode15s_amox\nNameError: name 'enzymic_amox' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name,ic \u001b[38;5;129;01min\u001b[39;00m inital_conditions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting...\u001b[39m\u001b[38;5;124m\"\u001b[39m,name,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m Time: \u001b[39m\u001b[38;5;124m\"\u001b[39m,datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mtime())\n\u001b[1;32m----> 6\u001b[0m     results[name] \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_cores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43mic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparam_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnding \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m Time: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mprint\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mtime()))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'enzymic_amox' is not defined"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "num_cores = 6  # Use all available cores\n",
    "results = {}\n",
    "for name,ic in inital_conditions.items():\n",
    "    print(\"Starting...\",name,\"\\t Time: \",datetime.datetime.now().time())\n",
    "    results[name] = Parallel(n_jobs=num_cores)(delayed(model_output)(np.concatenate((params,ic))) for params in param_values)\n",
    "    print(f\"Ending {name}\",\"\\t Time: \",print(datetime.datetime.now().time()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_clean = {}\n",
    "for name,result in results.items():\n",
    "    result_clean = []\n",
    "    for result_array in result:\n",
    "        if result_array.shape[0] == 201:\n",
    "            result_clean.append(result)\n",
    "        else:\n",
    "            result_clean.append(np.zeros((201,4)))\n",
    "    results_clean[name] = result_clean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Store the Si_list to a file\n",
    "with open('result_raw.pkl','wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "with open('result_clean.pkl', 'wb') as f:\n",
    "    pickle.dump(results_clean, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.analyze import sobol  # Correctly import analyze\n",
    "import numpy as np\n",
    "\n",
    "all_si = {}\n",
    "for name, results in result_clean.items():\n",
    "    Y = np.array(results)\n",
    "    print(\"Starting...\",name,\"\\t Time: \",datetime.datetime.now().time())\n",
    "\n",
    "    print(f\"Shape of Y: {Y.shape}\")\n",
    "    Si_list = []\n",
    "    for i in range(Y.shape[1]):  # Iterate over time points\n",
    "        for j in range(Y.shape[2]):  # Iterate over each output variable (4 outputs)\n",
    "            print(f\"Processing time point {i}/{Y.shape[1]}, output {j}/{Y.shape[2]}\", end='\\r')\n",
    "\n",
    "            # Perform Sobol analysis on the output variable j at time point i\n",
    "            Si = sobol.analyze(problem, Y[:, i, j], calc_second_order=True, print_to_console=False)\n",
    "            \n",
    "            # Store the result for each time point and output variable\n",
    "            Si_list.append(Si)\n",
    "\n",
    "            # Optionally print the first-order sensitivity indices for debugging\n",
    "            print(f\"S1 at time point {i}, output {j}: {Si['S1']}\")\n",
    "    all_si[name] = Si_list\n",
    "    print(f\"Ending {name}\",\"\\t Time: \",print(datetime.datetime.now().time()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_si_luci.pkl', 'wb') as f:\n",
    "    pickle.dump(all_si, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plots_folder = \"sobol_plots\"\n",
    "os.makedirs(plots_folder, exist_ok=True)\n",
    "outputs = ['CAB', 'CAN', 'CNH', 'CAOH']\n",
    "\n",
    "for name, Si_list in all_si.items():\n",
    "    Y = np.array(results_clean[name])\n",
    "    n_timepoints = Y.shape[1]\n",
    "    n_outputs = Y.shape[2]\n",
    "    output_dir = f\"sobol_plots/{name}\"\n",
    "    os.makedirs(output_dir,exist_ok=True)\n",
    "\n",
    "    # Generate and save the plots for each output\n",
    "\n",
    "    for j in range(n_outputs):  # Loop over each output variable\n",
    "        S1_values = np.array([Si_list[i]['S1'] for i in range(j, len(Si_list), n_outputs)])\n",
    "        ST_values = np.array([Si_list[i]['ST'] for i in range(j, len(Si_list), n_outputs)])\n",
    "        S2_values = np.array([Si_list[i]['S2'] for i in range(j, len(Si_list), n_outputs)])  # Second-order indices\n",
    "\n",
    "        # Plot S1 (First-order sensitivity indices) for each parameter across time points\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for k in range(S1_values.shape[1]):  # Loop over parameters\n",
    "            plt.plot(range(n_timepoints), S1_values[:, k], label=f'S1 - {problem[\"names\"][k]}')\n",
    "        plt.title(f'First-order Sobol indices (S1) for {outputs[j]}')\n",
    "        plt.xlabel('Time Point')\n",
    "        plt.ylabel('Sobol Index (S1)')\n",
    "        plt.legend(loc='best')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_dir, f'{name}_{outputs[j]}_S1.png'))\n",
    "        plt.close()\n",
    "\n",
    "        # Plot ST (Total-order sensitivity indices) for each parameter across time points\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for k in range(ST_values.shape[1]):  # Loop over parameters\n",
    "            plt.plot(range(n_timepoints), ST_values[:, k], label=f'ST - {problem[\"names\"][k]}')\n",
    "        plt.title(f'Total-order Sobol indices (ST) for {outputs[j]}')\n",
    "        plt.xlabel('Time Point')\n",
    "        plt.ylabel('Sobol Index (ST)')\n",
    "        plt.legend(loc='best')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_dir, f'{name}_{outputs[j]}_ST.png'))\n",
    "        plt.close()\n",
    "\n",
    "        # Aggregate S2 (Second-order indices) across time points into a heatmap\n",
    "        mean_S2 = np.mean(S2_values, axis=0)  # Mean across time points for each pair (n_params x n_params)\n",
    "        \n",
    "        # Plot a heatmap of the mean second-order Sobol indices\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(mean_S2, annot=True, cmap='viridis', xticklabels=problem['names'], yticklabels=problem['names'])\n",
    "        plt.title(f'Heatmap of Mean Second-order Sobol Indices (S2) for {outputs[j]}')\n",
    "        plt.savefig(os.path.join(output_dir, f'{name}_{outputs[j]}_S2_heatmap.png'))\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"Plots and heatmaps saved in: {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
